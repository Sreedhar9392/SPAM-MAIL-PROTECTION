{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Converting text data to numerical values\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection and Preprocessing\n",
    "raw_mail_data = pd.read_csv(\"mail_data.csv\")\n",
    "raw_mail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the null values with a null string\n",
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding: Labelling spam mail as 0 and ham(noon spam mails) as 1\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category', ] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category', ] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the data as text and labels\n",
    "X = mail_data['Message']\n",
    "Y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training data and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "# We transform the test data to feature vectors that can be used as input to the Logistic regression\n",
    "feature_extraction = TfidfVectorizer(min_df=1, stop_words='english', lowercase='True')\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test) # Only use transform so our dataset deosn't become biased\n",
    "\n",
    "# Convert Y_train and Y_test values as integers\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model\n",
    "# Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model .fit(X_train_features, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  0.9670181736594121\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the trained model\n",
    "# Prediction on training data:\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)\n",
    "print('Accuracy on training data: ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.9659192825112107\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the trained model\n",
    "# Prediction on test data:\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)\n",
    "print('Accuracy on test data: ', accuracy_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam\n"
     ]
    }
   ],
   "source": [
    "# Building a predicting system\n",
    "input_mail = [\"You gotfree tcikets to the beach. Check the family whatsapp!\"]\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "prediction = model.predict(input_data_features)\n",
    "if prediction[0] == '1':\n",
    "    print('Not Spam')\n",
    "else:\n",
    "    print('Spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91a2b9e919f0ae324536cb60d2992e7600ef7a863d730da7704c0273d5cf2cf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
